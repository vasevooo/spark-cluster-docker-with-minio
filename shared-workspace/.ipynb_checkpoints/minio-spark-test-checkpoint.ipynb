{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f03175bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dcdb1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PySpark version: 3.1.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Using PySpark version: {pyspark.__version__}\") # Should print 3.1.3\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MinioS3AAutoConfTest\") \\\n",
    "    .master(\"spark://jupyter-spark-master:7077\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1b78f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minio_endpoint_url = os.getenv('MINIO_ENDPOINT_URL', 'http://minio:9000')\n",
    "# Replace fallback values ONLY if not using environment variables\n",
    "minio_access_key = os.getenv('MINIO_ROOT_USER', 'YOUR_MINIO_ACCESS_KEY')\n",
    "minio_secret_key = os.getenv('MINIO_ROOT_PASSWORD', 'YOUR_MINIO_SECRET_KEY')\n",
    "# Use consistent bucket naming\n",
    "bucket_name = os.getenv('MINIO_DEFAULT_BUCKET', 'your-bucket-name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcbcbe09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring S3 client for endpoint: http://minio:9000\n",
      "Ensuring bucket 'test-bucket' exists...\n",
      "Bucket 'test-bucket' already exists.\n",
      "Bucket check/creation process finished.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Configuring S3 client for endpoint: {minio_endpoint_url}\")\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=minio_endpoint_url,\n",
    "    aws_access_key_id=minio_access_key,\n",
    "    aws_secret_access_key=minio_secret_key,\n",
    ")\n",
    "\n",
    "# --- Check and Create Bucket ---\n",
    "print(f\"Ensuring bucket '{bucket_name}' exists...\")\n",
    "try:\n",
    "    # Check if bucket exists. head_bucket throws an exception if it doesn't exist.\n",
    "    s3_client.head_bucket(Bucket=bucket_name)\n",
    "    print(f\"Bucket '{bucket_name}' already exists.\")\n",
    "except ClientError as e:\n",
    "    # Check if the error is specifically a \"Not Found\" or \"NoSuchBucket\" error\n",
    "    error_code = e.response.get('Error', {}).get('Code')\n",
    "    # MinIO might return 404 or NoSuchBucket depending on configuration/version\n",
    "    if error_code == '404' or 'NoSuchBucket' in str(e):\n",
    "        print(f\"Bucket '{bucket_name}' does not exist. Attempting to create...\")\n",
    "        try:\n",
    "            # Create the bucket\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "            print(f\"Bucket '{bucket_name}' created successfully.\")\n",
    "        except ClientError as creation_error:\n",
    "            print(f\"Error creating bucket '{bucket_name}': {creation_error}\")\n",
    "            # Decide if you want to stop execution if bucket creation fails\n",
    "            raise creation_error\n",
    "    else:\n",
    "        # Handle other potential errors (permissions, network issues, etc.)\n",
    "        print(f\"Error checking bucket status for '{bucket_name}': {e}\")\n",
    "        raise e\n",
    "\n",
    "print(\"Bucket check/creation process finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a69e623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DataFrame created:\n",
      "+-------+---+\n",
      "|   name| id|\n",
      "+-------+---+\n",
      "|  Alice|  1|\n",
      "|    Bob|  2|\n",
      "|Charlie|  3|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Sample Data\n",
    "data = [(\"Alice\", 1), (\"Bob\", 2), (\"Charlie\", 3)]\n",
    "columns = [\"name\", \"id\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "print(\"Sample DataFrame created:\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3dfb257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define S3A Path\n",
    "output_path = f\"s3a://{bucket_name}/test-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57275d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to write DataFrame to: s3a://test-bucket/test-data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote data to MinIO.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 3. Write DataFrame to MinIO\n",
    "print(f\"Attempting to write DataFrame to: {output_path}\")\n",
    "try:\n",
    "    df.write.mode(\"overwrite\").parquet(output_path)\n",
    "    print(\"Successfully wrote data to MinIO.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to MinIO: {e}\")\n",
    "    # Print stack trace for more details if needed\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    spark.stop()\n",
    "    raise e # Re-raise exception to stop the cell execution clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05f5fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read data back from: s3a://test-bucket/test-data\n",
      "Successfully read data back from MinIO:\n",
      "+-------+---+\n",
      "|   name| id|\n",
      "+-------+---+\n",
      "|Charlie|  3|\n",
      "|  Alice|  1|\n",
      "|    Bob|  2|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Read Data back from MinIO\n",
    "print(f\"Attempting to read data back from: {output_path}\")\n",
    "try:\n",
    "    df_read = spark.read.parquet(output_path)\n",
    "    print(\"Successfully read data back from MinIO:\")\n",
    "    df_read.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading from MinIO: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be720082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test finished.\n"
     ]
    }
   ],
   "source": [
    "# 5. Stop SparkSession\n",
    "spark.stop()\n",
    "print(\"Test finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
